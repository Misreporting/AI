Email sent January 23, 2017: 
Dear all,

I wanted to sent a separate note on the topical issue of generative AIs. 

As you have probably noticed, in the past month, many newspapers have published articles about the capabilities of generative artificial intelligence programs (AIs) such as Open AI’s ChatGPT. For instance, at the end of last term, I gave the epi methods 1 midterm to Chat GPT-3, and it scored 85%. It also got some individual final exam problems correct, so may have scored about the same on the final. 

ChatGPT is not the only generative AI. I’ve attached a screen shot of an AI-generated 1 paragraph literature review about the association between depression and vaping in adolescents that includes citations in the HTML. It does a so-so job, although of note it cites two dubious advocacy groups: a public health group heavily funded by industries like oil companies and soft drink companies and a group listed as an anti-LGBT hate group by the Southern Poverty Law Center. Less important, it cites some press releases rather than the original papers. 
https://phind.com/search?q=what+is+the+association+between+depression+and+vaping+in+US+adolescents%2C+based+on+only+peer-reviewed+journal+articles.

About 7 years ago, I ran into an old statistician colleague from RAND who had moved to Kaiser, and he said they were using generative AI for automated statistical analysis, and the automation generated what was in his words "some B+ analyses, but to get solid A analysis, we need people.” It seems like these text generation programs are like the automated code generators.

More importantly, you’re taking this class so that you can understand and produce research, speak knowledgeably at job interviews, talking with colleagues, and when you’re presenting your research at the APHA annual meeting over the coming decades. At present, an AI can’t substitute for the proverbial 10,000 hours for mastery of a field or for human judgement and ethics/morality. It may be that AI can never substitute: ethicists have written that we can’t allow lethal autonomous weapons (i.e., “killer robots”) in war precisely because of the moral implications of the decisions that they make. Public health is not warfare, but it also involves ethical issues.

Finally, academic honesty requires citing sources, including AIs. For instance, here’s MLA style for citing an AI; I haven’t found equivalent for APA and AMA: https://style.mla.org/citing-artificial-intelligence/ 
