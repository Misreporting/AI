<p>
    John McCarthy created the term “artificial intelligence” for a Dartmouth
    summer workshop in 1956 on how the then-recent advances in computational
    capacity could simulate intelligence; it turns out that the summer workshop
    did not exhaust the topic. One of the fundamental and unresolved
    controversies within AI is whether AI must follow an algorithm, a defined
    process to reach a result, or whether a black-box neural network approach
    that yields a matrix of weighted connections that does not follow a
    definable process. AI has had genuine advances under both paradigms. Because
    an algorithmic approach can reach its results by following a known and
    defined process, its answers as true if the process was correctly defined.
    By contrast, a black box neural network approach is only statistical and
    therefore will always have some prevalence of incorrect answers.
</p>
<p>
    In its 70-year history, AI has had both genuine accomplishments and what MIT
    artificial intelligence lab founding director Rodney Brooks calls “hype
    cycles.” Confusingly, we are in the middle of both. Demis Hassabis and John
    Jumper won the 2024 Nobel Prize in chemistry for their Deep Mind protein
    folding analysis, a problem that was not believed to be solvable on any
    reasonable time frame. On the hype side, generative AI is a product, and the
    primary goal of generative AI companies is to maximize their investors’
    financial returns rather than to deliver a beneficial or safe product.
    Academia must distinguish between advances and AI marketing tactics designed
    to increase sales. The hype side is particularly complicated by the fact
    that AI companies are responsible for most recent gains in financial
    markets, so society has now invested its financial future in these products.
    Everyone has a financial conflict of interest in continued steady growth,
    whether or not they realize it.
</p>
<p>
    In the 1980s, Rodney Brooks, the founding director of the MIT Computer
    Science and Artificial Intelligence Laboratory (CSAIL), and his lab
    developed a soda can robot that did not build an internal map of the space
    in which it operates: the robot would wander around randomly until it
    identified a soda can; it would pick up the soda can, and then it would
    wander around randomly until it found the recycling bin, where it would
    deposit the can and then repeat the process. This method of random wandering
    may sound familiar to robot vacuum cleaner users: Brooks founded the company
    iRobot, which developed the Roomba vacuum cleaner that would wander at
    random; with advances in storage and memory, the vacuum did eventually map
    its space. The military safety applications of this approach are less
    well-known than the robot vacuum, but the wander-at-random paradigm was used
    for activities that would be too dangerous for humans, such as de-mining and
    searching the World Trade Center complex rubble after the 9/11 terrorist
    attack.
</p>
<p>
    My personal experience with AI spans over 30 years. As an undergraduate at
    Harvard College majoring in math and physics, I took the undergraduate
    introductory course for computer science majors for which I wrote a
    simulation of how people play the card game Set, and I also took the
    computer science major course in artificial intelligence, Computer Science
    181; I also participated in a small AI reading group led by a graduate
    student where we learned the history of AI.
</p>
<p>
    tl; dr: What to know about AI:
</p>
<p>
    1.        AI has been going for decades, and it is only recently that the
    general public noticed it.
</p>
<p>
    2.        AI has genuine accomplishments: e.g., AI protein folding won the
    2024 Nobel Prize in Chemistry.
</p>
<p>
    3.        AI also has hype cycles, and AI companies are trying to sell a
    product.
</p>
<p>
    AI resources
</p>
<p>
    1.        History of AI: autonomous robots, chatbots.
</p>
<p>
    a.        The term “artificial intelligence” was invented in 1956 by John
    McCarthy for a Dartmouth summer program.
</p>
<p>
    b.        Eliza, 1966. Eliza is a Rogerian psychotherapy chatbot that has
    been widely available. For example, it’s built into the emacs text editor.
    You can use it now:
    <a href="https://sites.google.com/view/elizaarchaeology/try-eliza">
        https://sites.google.com/view/elizaarchaeology/try-eliza
    </a>
</p>
<p>
    c.        DENDRAL, an expert system for determining chemical structures,
    1960s: Computers, Artificial Intelligence, and Expert Systems in Biomedical
    Research,
    <a href="https://profiles.nlm.nih.gov/spotlight/bb/feature/ai">
        https://profiles.nlm.nih.gov/spotlight/bb/feature/ai
    </a>
</p>
<p>
    d.        Jeremy Bernstein, A.I.: Martin Minsky’s vision of the future, New
    Yorker, December 6, 1981.
</p>
<p>
    e.        Bruce Buchanan, Research on Expert Systems, Office of Naval
    Research, National Science Foundation, March 1981.
</p>
<p>
    f.           Rodney Brooks, MIT AI lab soda can-collecting robot, 1986
    <a href="https://www.youtube.com/watch?v=YtNKuwiVYm0">
        https://www.youtube.com/watch?v=YtNKuwiVYm0
    </a>
</p>
<p>
    g.         Rodney Brooks, how robots will invade our lives, Ted Talk, 2003.
    Rodney Brooks’s lab invented the Roomba, and he founded iRobot. iRobot’s
    tactical military robot searched parts of the World Trade Center for
    survivors.
    <a href="https://www.youtube.com/watch?v=UdyRmdv-KiY">
        https://www.youtube.com/watch?v=UdyRmdv-KiY
    </a>
</p>
<p>
    2.        AI expert systems in medicine and sciences
</p>
<p>
    a.        McCarthy J. Some expert systems need common sense. Ann N Y Acad
    Sci. 1984;426:129-137. doi:10.1111/j.1749-6632.1984.tb16516.x
</p>
<p>
    b.        Shortline EH. Medical Expert Systems: Knowledge Tools for
    Physicians. In Medical informatics [Special Issue]. WestJ Med 1986Dec;
    145:830-839
</p>
<p>
    c.        Berner ES, Webster GD, Shugerman AA, et al. Performance of four
    computer-based diagnostic systems. <em>N Engl J Med</em>.
    1994;330(25):1792-1796. doi:10.1056/NEJM199406233302506
</p>
<p>
    d.        Expert Systems of the 1980s: Joseph Williams. 1990. When expert
    systems are wrong. In Proceedings of the 1990 ACM SIGBDP conference on
    Trends and directions in expert systems (SIGBDP '90). Association for
    Computing Machinery, New York, NY, USA, 661–669.
    <a href="https://doi.org/10.1145/97709.97761">
        https://doi.org/10.1145/97709.97761
    </a>
</p>
<p>
    e.        John Durkin, Application of Expert Systems in the Sciences, OHIO
    J. SCI. 90 (5): 171-179, 1990.
    <a
        href="https://kb.osu.edu/server/api/core/bitstreams/98710464-d567-5dac-a77f-53e03a1a6ec9/content"
    >
        https://kb.osu.edu/server/api/core/bitstreams/98710464-d567-5dac-a77f-53e03a1a6ec9/content
    </a>
</p>
<p>
    f.           Current expert systems: Josh Tamayo-Sarver, I’m an ER doctor:
    Here’s what I found when I asked ChatGPT to diagnose my patients: ChatGPT
    recently passed the U.S. Medical Licensing Exam, but using it for a
    real-world medical diagnosis would quickly turn deadly. 3/13/23,
    <a
        href="https://www.fastcompany.com/90863983/chatgpt-medical-diagnosis-emergency-room"
    >
        https://www.fastcompany.com/90863983/chatgpt-medical-diagnosis-emergency-room
    </a>
</p>
<p>
    a.        Modern expert systems:  Chen W, Howard K, Gorham G, O'Bryan CM,
    Coffey P, Balasubramanya B, Abeyaratne A, Cass A. Design, effectiveness, and
    economic outcomes of contemporary chronic disease clinical decision support
    systems: a systematic review and meta-analysis. J Am Med Inform Assoc. 2022
    Sep 12;29(10):1757-1772. doi: 10.1093/jamia/ocac110.
</p>
<p>
    g.         Bright TJ, Wong A, Dhurjati R, et al. Effect of clinical
    decision-support systems: a systematic review. Ann Intern Med.
    2012;157(1):29-43. doi:10.7326/0003-4819-157-1-201207030-00450
</p>
<p>
    3.        Contemporary AI computation: the current era in AI was made
    possible by using computer chips that were originally graphics processor
    units, an innovation by the company NVIDIA, which is currently the most
    valuable company in the world.
</p>
<p>
    a.        Wired Staff, Nvidia: Meet NVIDIA CEO Jen-Hsun Huang, the man who
    plans to make the CPU obsolete. Wired, July 1, 2002.
    <a href="https://www.wired.com/2002/07/nvidia/">
        https://www.wired.com/2002/07/nvidia/
    </a>
</p>
<p>
    b.        Sam Shead, Nvidia's got a cunning plan to keep powering the AI
    revolution: Nvidia’s artificial intelligence journey started with cats. Now
    it's heading to the Kitchen, Wired, February 27, 2019.
    <a href="https://www.wired.com/story/nvidia-artificial-intelligence-gpu/">
        https://www.wired.com/story/nvidia-artificial-intelligence-gpu/
    </a>
</p>
<p>
    c.        Jason Kehe, Angelina Jolie Was Right About Computers: “RISC
    architecture is gonna change everything.” Those absurdly geeky, incredibly
    prophetic words were spoken 30 years ago. Today, they’re somehow truer than
    ever. Wired, March 25, 2025.
    <a
        href="https://www.wired.com/story/angelina-jolie-was-right-about-risc-architecture/"
    >
        https://www.wired.com/story/angelina-jolie-was-right-about-risc-architecture/
    </a>
</p>
<p>
    4.        AI applications: protein folding, drug discovery
</p>
<p>
    a.
    <a
        href="https://sunydmc-my.sharepoint.com/personal/janet_rosenbaum_downstate_edu/Documents/Shared%20teaching%20files/Epidemiology5205-7202-fall2025/Session%200%20Bullshit%20machines/NOVA%20AI%20revolution"
    >
        NOVA AI revolution
    </a>
    .
    <a href="https://www.pbs.org/wgbh/nova/video/ai-revolution/">
        https://www.pbs.org/wgbh/nova/video/ai-revolution/
    </a>
</p>
<p>
    b.
    <a
        href="https://sunydmc-my.sharepoint.com/personal/janet_rosenbaum_downstate_edu/Documents/Shared%20teaching%20files/Epidemiology5205-7202-fall2025/Session%200%20Bullshit%20machines/Thinking%20Game"
    >
        Thinking Game
    </a>
    :
    <a href="https://www.youtube.com/watch?v=d95J8yzvjbQ">
        https://www.youtube.com/watch?v=d95J8yzvjbQ
    </a>
</p>
<p>
    5.        Limitations of AI
</p>
<p>
    a.        Ted Chiang, “ChatGPT Is a Blurry JPEG of the Web: OpenAI’s chatbot
    offers paraphrases, whereas Google offers quotes. Which do we prefer?” New
    Yorker, February 9, 2023
</p>
<p>
    b.        AI advances will have limited impact on the economy and will
    displace few jobs. Skip the heavy math here.  Daron Acemoglu won the Nobel
    Memorial Prize in Economics in 2024. Daron Acemoglu, The Simple
    Macroeconomics of AI. MIT Shaping the Future of Work Initiative, May 12,
    2024.
</p>
<p>
    c.        Niederhoffer K, Rosen Kellerman G, Lee A, Liebscher A, Rapuano K,
    Hancock, JT. AI-Generated “Workslop” Is Destroying Productivity, Harvard
    Business Review, September 22, 2025.
    <a
        href="https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity"
    >
        https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity
    </a>
</p>
<p>
    d.        Jan Walraven, Belgian AI scientists resist the use of AI in
    academia, October 24, 2025, Apache: Stelt Scherp,
    <a
        href="https://apache.be/2025/10/24/belgian-ai-scientists-resist-use-ai-academia"
    >
        https://apache.be/2025/10/24/belgian-ai-scientists-resist-use-ai-academia
    </a>
</p>
<p>
    e.        Moore J, Grabb D, Agnew W, Klyman K, Chancellor S, Ong DC, Haber
    N. Expressing stigma and inappropriate responses prevents LLMs from safely
    replacing mental health providers. In: Proceedings of the 2025 ACM
    Conference on Fairness, Accountability, and Transparency 2025 Jun 23 (pp.
    599-627).
    <a href="https://dl.acm.org/doi/10.1145/3715275.3732039">
        https://dl.acm.org/doi/10.1145/3715275.3732039
    </a>
</p>
<p>
    6.        Adverse effects of AI on users
</p>
<p>
    a.        Deskilling: Anastasia Berg and A. Papazoglou, The Philosopher and
    the News: How to prevent AI from making us stupid? The Philosopher Podcast,
    Nov 24, 2025.
    <a href="https://www.youtube.com/watch?v=8eZP86w5dpE">
        https://www.youtube.com/watch?v=8eZP86w5dpE
    </a>
</p>
<p>
    b.        AI psychosis:
    <a href="https://www.youtube.com/watch?v=Xx7WwHHrAD0">
        AI psychosis from Eliza
    </a>
    (<a href="https://www.youtube.com/watch?v=Xx7WwHHrAD0">https://www.youtube.com/watch?v=Xx7WwHHrAD0</a>)
</p>
<p>
    c.        Lila Shroff, ChatGPT Gave Instructions for Murder,
    Self-Mutilation, and Devil Worship: OpenAI’s chatbot also said “Hail Satan.”
    July 24, 2025.
    <a
        href="https://www.theatlantic.com/technology/archive/2025/07/chatgpt-ai-self-mutilation-satanism/683649/"
    >
        https://www.theatlantic.com/technology/archive/2025/07/chatgpt-ai-self-mutilation-satanism/683649/
    </a>
</p>
<p>
    7.        Rodney Brooks: The realities and myths of AI.
    <a href="https://www.youtube.com/watch?v=yQxpn9LctO8">
        https://www.youtube.com/watch?v=yQxpn9LctO8
    </a>
</p>
<p>
    8.        Self-driving applications: food delivery robots in LA and Chicago
</p>
<p>
    a.        Chicago Like a Local,
    <a href="https://www.youtube.com/watch?v=F98gWee5AfI">
        The Thing About These Food Delivery Robots…
    </a>
    , Aug 21, 2025.
</p>
<p>
    b.        The Verge,
    <a href="https://www.youtube.com/watch?v=IzM4wXROdLM">
        The secret behind these autonomous delivery robots
    </a>
    , Oct 31, 2023,
</p>
<p>
    c.        Injury from food delivery robots in Chicago:
    <a href="https://www.youtube.com/watch?v=zg6pdO7-X7U">
        https://www.youtube.com/watch?v=zg6pdO7-X7U
    </a>
</p>
<p>
    9.        Adverse effects of AI on workers training the AI
</p>
<p>
    a.        Training AI takes heavy toll on Kenyans working for $2 an hour, 60
    Minutes.
    <a href="https://www.youtube.com/watch?v=qZS50KXjAX0">
        https://www.youtube.com/watch?v=qZS50KXjAX0
    </a>
</p>
<p>
    b.        Billy Perrigo, Exclusive: OpenAI Used Kenyan Workers on Less Than
    $2 Per Hour to Make ChatGPT Less Toxic. Time Magazine. January 18, 2023.
    <a href="https://time.com/6247678/openai-chatgpt-kenya-workers/">
        https://time.com/6247678/openai-chatgpt-kenya-workers/
    </a>
</p>
<p>
    10.  AI and plagiarism:
</p>
<p>
    a.        Earp, B.D., Yuan, H., Koplin, J. et al. LLM use in scholarly
    writing poses a provenance problem. Nat Mach Intell (2025).
    <a
        href="https://www.nature.com/articles/s42256-025-01159-8.epdf?sharing_token=xJmd4cDnq2FxFbfAnUEO8tRgN0jAjWel9jnR3ZoTv0PvnbYm4DP1YR2ybrBtLKE2-ci89m0C22f_VxZ6qtDz6gdTCqxdpdoWgGrsoFGUIgaxb78BHjLOCrIRP22lGITtLPPek5CCq6IFWAXlPQcqOE3r_1m5NRTJunaxyXptY-c%3D"
    >
        https://doi.org/10.1038/s42256-025-01159-8
    </a>
</p>
<p>
    11.  Critiques:
</p>
<p>
    a.        Guest et al. (2025).
    <a href="https://philarchive.org/archive/GUEATU">
        Against the Uncritical Adoption of ‘AI’ Technologies in Academia
    </a>
    .
    <a href="https://doi.org/10.5281/zenodo.17065099">
        https://doi.org/10.5281/zenodo.17065099
    </a>
</p>
<p>
    12.  Automated feedback for classroom instruction
</p>
<p>
    a.        Stevenson M, Critical Interpretative Synthesis: The Integration of
    Automated Writing Evaluation into Classroom Writing Instruction, Computers
    and Composition 42 (2016) 1–16
</p>
<p>
    b.        Menary R. Writing as thinking.  Language Sciences, 2007;
    29:621–632.
</p>
<p>
    13.  Intellectual property and AI: Analogy with music sampling of the 1980s
</p>
<p>
    a.        Andrew Goodwin, Sample and hold: pop music in the digital age of
    reproduction,
    <a href="https://doi.org/10.1111/j.1467-8705.1988.tb00315.x">
        https://doi.org/10.1111/j.1467-8705.1988.tb00315.x
    </a>
</p>
<p>
    b.        Kyle Chayka, “Is AI stealing from Artists? According to the lawyer
    behind a new class-action suit, every image that a generative tool produces
    ‘is an infringing, derivative work.’ ” New Yorker,
</p>
<p>
    c.        Hutcheon L. Pumping Irony: Strength through Sampling. In Culture
    Lab 1. Ed. Brian Boigon. New York: Princeton Architectural Press, 1993.
    127-36.
</p>
<p>
    d.        Wikipedia entry: “M/A/R/R/S. Pump up the volume”. Available at:
    <a href="https://en.wikipedia.org/wiki/Pump_Up_the_Volume_(song)">
        https://en.wikipedia.org/wiki/Pump_Up_the_Volume_(song)
    </a>
</p>
<p>
    e.        M/A/R/R/S. Pump up the volume, 1987. Digital media. Available at:
    <a href="https://www.youtube.com/watch?v=w9gOQgfPW4Y">
        https://www.youtube.com/watch?v=w9gOQgfPW4Y
    </a>
</p>
<p>
    f.           Adam Baldwin,
    <em>
        Music Sampling and the De Minimis Defense: A Copyright Law Standard
    </em>
    , 19 UIC REV. INTELL. PROP. L. 310 (2020).
</p>
