# AI
Artificial intelligence annotated bibliography

John McCarthy created the term “artificial intelligence” for a Dartmouth summer workshop in 1956 on how the then-recent advances in computational capacity could simulate intelligence; it turns out that the summer workshop did not exhaust the topic. One of the fundamental and unresolved controversies within AI is whether AI must follow an algorithm, a defined process to reach a result, or whether a black-box neural network approach that yields a matrix of weighted connections that does not follow a definable process. AI has had genuine advances under both paradigms. Because an algorithmic approach can reach its results by following a known and defined process, its answers as true if the process was correctly defined. By contrast, a black box neural network approach is only statistical and therefore will always have some prevalence of incorrect answers.  
In its 70-year history, AI has had both genuine accomplishments and what MIT artificial intelligence lab founding director Rodney Brooks calls “hype cycles.” Confusingly, we are in the middle of both. Demis Hassabis and John Jumper won the 2024 Nobel Prize in chemistry for their Deep Mind protein folding analysis, a problem that was not believed to be solvable on any reasonable time frame. On the hype side, generative AI is a product, and the primary goal of generative AI companies is to maximize their investors’ financial returns rather than to deliver a beneficial or safe product. Academia must distinguish between advances and AI marketing tactics designed to increase sales. The hype side is particularly complicated by the fact that AI companies are responsible for most recent gains in financial markets, so society has now invested its financial future in these products. Everyone has a financial conflict of interest in continued steady growth, whether or not they realize it. 
In the 1980s, Rodney Brooks, the founding director of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL), and his lab developed a soda can robot that did not build an internal map of the space in which it operates: the robot would wander around randomly until it identified a soda can; it would pick up the soda can, and then it would wander around randomly until it found the recycling bin, where it would deposit the can and then repeat the process. This method of random wandering may sound familiar to robot vacuum cleaner users: Brooks founded the company iRobot, which developed the Roomba vacuum cleaner that would wander at random; with advances in storage and memory, the vacuum did eventually map its space. The military safety applications of this approach are less well-known than the robot vacuum, but the wander-at-random paradigm was used for activities that would be too dangerous for humans, such as de-mining and searching the World Trade Center complex rubble after the 9/11 terrorist attack. 
	My personal experience with AI spans over 30 years. As an undergraduate at Harvard College majoring in math and physics, I took the undergraduate introductory course for computer science majors for which I wrote a simulation of how people play the card game Set, and I also took the computer science major course in artificial intelligence, Computer Science 181; I also participated in a small AI reading group led by a graduate student where we learned the history of AI.
tl; dr: What to know about AI: 
1.	AI has been going for decades, and it is only recently that the general public noticed it.  
2.	AI has genuine accomplishments: e.g., AI protein folding won the 2024 Nobel Prize in Chemistry. 
3.	AI also has hype cycles, and AI companies are trying to sell a product.

AI resources
1.	History of AI: autonomous robots, chatbots. 
a.	The term “artificial intelligence” was invented in 1956 by John McCarthy for a Dartmouth summer program.
b.	Eliza, 1966. Eliza is a Rogerian psychotherapy chatbot that has been widely available. For example, it’s built into the emacs text editor. You can use it now: https://sites.google.com/view/elizaarchaeology/try-eliza 
c.	DENDRAL, an expert system for determining chemical structures, 1960s: Computers, Artificial Intelligence, and Expert Systems in Biomedical Research, https://profiles.nlm.nih.gov/spotlight/bb/feature/ai 
d.	Jeremy Bernstein, A.I.: Martin Minsky’s vision of the future, New Yorker, December 6, 1981. 
e.	Bruce Buchanan, Research on Expert Systems, Office of Naval Research, National Science Foundation, March 1981. 
f.	Rodney Brooks, MIT AI lab soda can-collecting robot, 1986 https://www.youtube.com/watch?v=YtNKuwiVYm0 
g.	Rodney Brooks, how robots will invade our lives, Ted Talk, 2003. Rodney Brooks’s lab invented the Roomba, and he founded iRobot. iRobot’s tactical military robot searched parts of the World Trade Center for survivors. https://www.youtube.com/watch?v=UdyRmdv-KiY 
2.	AI expert systems in medicine and sciences
a.	McCarthy J. Some expert systems need common sense. Ann N Y Acad Sci. 1984;426:129-137. doi:10.1111/j.1749-6632.1984.tb16516.x 
b.	Shortline EH. Medical Expert Systems: Knowledge Tools for Physicians. In Medical informatics [Special Issue]. WestJ Med 1986Dec; 145:830-839
c.	Berner ES, Webster GD, Shugerman AA, et al. Performance of four computer-based diagnostic systems. N Engl J Med. 1994;330(25):1792-1796. doi:10.1056/NEJM199406233302506 
d.	Expert Systems of the 1980s: Joseph Williams. 1990. When expert systems are wrong. In Proceedings of the 1990 ACM SIGBDP conference on Trends and directions in expert systems (SIGBDP '90). Association for Computing Machinery, New York, NY, USA, 661–669. https://doi.org/10.1145/97709.97761 
e.	John Durkin, Application of Expert Systems in the Sciences, OHIO J. SCI. 90 (5): 171-179, 1990. https://kb.osu.edu/server/api/core/bitstreams/98710464-d567-5dac-a77f-53e03a1a6ec9/content 
f.	Current expert systems: Josh Tamayo-Sarver, I’m an ER doctor: Here’s what I found when I asked ChatGPT to diagnose my patients: ChatGPT recently passed the U.S. Medical Licensing Exam, but using it for a real-world medical diagnosis would quickly turn deadly. 3/13/23, https://www.fastcompany.com/90863983/chatgpt-medical-diagnosis-emergency-room 
a.	Modern expert systems:  Chen W, Howard K, Gorham G, O'Bryan CM, Coffey P, Balasubramanya B, Abeyaratne A, Cass A. Design, effectiveness, and economic outcomes of contemporary chronic disease clinical decision support systems: a systematic review and meta-analysis. J Am Med Inform Assoc. 2022 Sep 12;29(10):1757-1772. doi: 10.1093/jamia/ocac110.
g.	Bright TJ, Wong A, Dhurjati R, et al. Effect of clinical decision-support systems: a systematic review. Ann Intern Med. 2012;157(1):29-43. doi:10.7326/0003-4819-157-1-201207030-00450
3.	Contemporary AI computation: the current era in AI was made possible by using computer chips that were originally graphics processor units, an innovation by the company NVIDIA, which is currently the most valuable company in the world.  
a.	Wired Staff, Nvidia: Meet NVIDIA CEO Jen-Hsun Huang, the man who plans to make the CPU obsolete. Wired, July 1, 2002. https://www.wired.com/2002/07/nvidia/ 
b.	Sam Shead, Nvidia's got a cunning plan to keep powering the AI revolution: Nvidia’s artificial intelligence journey started with cats. Now it's heading to the Kitchen, Wired, February 27, 2019. https://www.wired.com/story/nvidia-artificial-intelligence-gpu/ 
c.	Jason Kehe, Angelina Jolie Was Right About Computers: “RISC architecture is gonna change everything.” Those absurdly geeky, incredibly prophetic words were spoken 30 years ago. Today, they’re somehow truer than ever. Wired, March 25, 2025. https://www.wired.com/story/angelina-jolie-was-right-about-risc-architecture/ 
4.	AI applications: protein folding, drug discovery
a.	NOVA AI revolution. https://www.pbs.org/wgbh/nova/video/ai-revolution/
b.	Thinking Game: https://www.youtube.com/watch?v=d95J8yzvjbQ 
5.	Limitations of AI
a.	Ted Chiang, “ChatGPT Is a Blurry JPEG of the Web: OpenAI’s chatbot offers paraphrases, whereas Google offers quotes. Which do we prefer?” New Yorker, February 9, 2023
b.	AI advances will have limited impact on the economy and will displace few jobs. Skip the heavy math here.  Daron Acemoglu won the Nobel Memorial Prize in Economics in 2024. Daron Acemoglu, The Simple Macroeconomics of AI. MIT Shaping the Future of Work Initiative, May 12, 2024. 
c.	Niederhoffer K, Rosen Kellerman G, Lee A, Liebscher A, Rapuano K, Hancock, JT. AI-Generated “Workslop” Is Destroying Productivity, Harvard Business Review, September 22, 2025. https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity 
d.	Jan Walraven, Belgian AI scientists resist the use of AI in academia, October 24, 2025, Apache: Stelt Scherp, https://apache.be/2025/10/24/belgian-ai-scientists-resist-use-ai-academia 
e.	Moore J, Grabb D, Agnew W, Klyman K, Chancellor S, Ong DC, Haber N. Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers. In: Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency 2025 Jun 23 (pp. 599-627). https://dl.acm.org/doi/10.1145/3715275.3732039 
6.	Adverse effects of AI on users
a.	Deskilling: Anastasia Berg and A. Papazoglou, The Philosopher and the News: How to prevent AI from making us stupid? The Philosopher Podcast, Nov 24, 2025. https://www.youtube.com/watch?v=8eZP86w5dpE 
b.	AI psychosis: AI psychosis from Eliza (https://www.youtube.com/watch?v=Xx7WwHHrAD0)
c.	Lila Shroff, ChatGPT Gave Instructions for Murder, Self-Mutilation, and Devil Worship: OpenAI’s chatbot also said “Hail Satan.” July 24, 2025. https://www.theatlantic.com/technology/archive/2025/07/chatgpt-ai-self-mutilation-satanism/683649/ 
7.	Rodney Brooks: The realities and myths of AI. https://www.youtube.com/watch?v=yQxpn9LctO8
8.	Self-driving applications: food delivery robots in LA and Chicago
a.	Chicago Like a Local, The Thing About These Food Delivery Robots…, Aug 21, 2025. 
b.	The Verge, The secret behind these autonomous delivery robots, Oct 31, 2023,  
c.	Injury from food delivery robots in Chicago: https://www.youtube.com/watch?v=zg6pdO7-X7U 
9.	Adverse effects of AI on workers training the AI 
a.	Training AI takes heavy toll on Kenyans working for $2 an hour, 60 Minutes. https://www.youtube.com/watch?v=qZS50KXjAX0
b.	Billy Perrigo, Exclusive: OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic. Time Magazine. January 18, 2023. https://time.com/6247678/openai-chatgpt-kenya-workers/  
10.	AI and plagiarism:
a.	Earp, B.D., Yuan, H., Koplin, J. et al. LLM use in scholarly writing poses a provenance problem. Nat Mach Intell (2025). https://doi.org/10.1038/s42256-025-01159-8
11.	Critiques:
a.	Guest et al. (2025). Against the Uncritical Adoption of ‘AI’ Technologies in Academia. https://doi.org/10.5281/zenodo.17065099 
12.	Automated feedback for classroom instruction
a.	Stevenson M, Critical Interpretative Synthesis: The Integration of Automated Writing Evaluation into Classroom Writing Instruction, Computers and Composition 42 (2016) 1–16
b.	Menary R. Writing as thinking.  Language Sciences, 2007; 29:621–632.  
13.	Intellectual property and AI: Analogy with music sampling of the 1980s
a.	Andrew Goodwin, Sample and hold: pop music in the digital age of reproduction, https://doi.org/10.1111/j.1467-8705.1988.tb00315.x 
b.	Kyle Chayka, “Is AI stealing from Artists? According to the lawyer behind a new class-action suit, every image that a generative tool produces ‘is an infringing, derivative work.’ ” New Yorker, 
c.	Hutcheon L. Pumping Irony: Strength through Sampling. In Culture Lab 1. Ed. Brian Boigon. New York: Princeton Architectural Press, 1993. 127-36.
d.	Wikipedia entry: “M/A/R/R/S. Pump up the volume”. Available at: https://en.wikipedia.org/wiki/Pump_Up_the_Volume_(song) 
e.	M/A/R/R/S. Pump up the volume, 1987. Digital media. Available at: https://www.youtube.com/watch?v=w9gOQgfPW4Y 
f.	Adam Baldwin, Music Sampling and the De Minimis Defense: A Copyright Law Standard, 19 UIC REV. INTELL. PROP. L. 310 (2020). 

